{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df44c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import migKeyPoint.utils.YAMLtools as yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7c70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = yt.load_configuration('../master_configuration.yaml')['yoloConf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fa360f",
   "metadata": {},
   "source": [
    "### Let's generate our keypoints as we did in part 1. I'll do this more succinctly this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84223f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class initial_data_processing:\n",
    "    def __init__(self,datafile):\n",
    "        self.datafile = datafile #path to simulated ER dataframe\n",
    "        self.data = self.load_data()\n",
    "        self.data = self.initial_data_transforms()\n",
    "        \n",
    "    def load_data(self):\n",
    "        df = pd.read_feather(self.datafile)\n",
    "        return df\n",
    "    \n",
    "    def initial_data_transforms(self):\n",
    "        def find_head(df,i):\n",
    "            tmp = df.iloc[i]\n",
    "            indices = pd.Series(tmp['q']).nlargest(3).index.to_numpy()\n",
    "            return np.median(tmp['x'][indices]),np.median(tmp['y'][indices])\n",
    "        xs = []\n",
    "        ys = []\n",
    "        print('Adding head points to data')\n",
    "        for i in tqdm(range(0,len(self.data))):\n",
    "            x,y = find_head(self.data,i)\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "        self.data['xhead'] = xs\n",
    "        self.data['yhead'] = ys\n",
    "        self.data['htlength'] = np.sqrt((self.data['xvtx']-self.data['xhead'])**2+(self.data['yvtx']-self.data['yhead'])**2)\n",
    "        self.data['xvtx'] = self.data['xvtx']-self.data['x'].apply(lambda x: x.min())+conf['cameraX']//2\n",
    "        self.data['yvtx'] = self.data['yvtx']-self.data['y'].apply(lambda x: x.min())+conf['cameraY']//2\n",
    "        self.data['xhead'] = self.data['xhead']-self.data['x'].apply(lambda x: x.min())+conf['cameraX']//2\n",
    "        self.data['yhead'] = self.data['yhead']-self.data['y'].apply(lambda x: x.min())+conf['cameraY']//2\n",
    "\n",
    "        self.data['x'] = self.data['x'].apply(lambda x: x-x.min()+conf['cameraX']//2)\n",
    "        self.data['y'] = self.data['y'].apply(lambda x: x-x.min()+conf['cameraY']//2)\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54072695",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERs = initial_data_processing('../simulation/ERs_cont_spectrum_correctE.feather').data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d263bd71",
   "metadata": {},
   "source": [
    "# Generate keypoints like in part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae466bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "class generate_keypoints:\n",
    "    '''Class takes a sparse image, rotates it so the head and tail are vertically aligned.\n",
    "    Then it partitions the interval between the head and tail into n_outputs + 2 equally spaced subdivisions\n",
    "    and records the (x',y') coordinate of either (a) the max intensity [if the mode parameter is set to 'max']\n",
    "    or (b), the median (x',y') over the 9 most intense pixels in each partition. The code then rotates the set of\n",
    "    (x',y')s back to the original image orientation, which are our keypoints!'''\n",
    "    \n",
    "    def __init__(self,df,i,n_outputs=1,dim=(2048,1152),mode='max'):\n",
    "        if mode.lower() != 'max' and mode.lower() != 'median':\n",
    "            raise ValueError(\"mode must be 'max' or 'median'\")\n",
    "        self.mode = mode.lower()\n",
    "        evt = df.iloc[i]\n",
    "        self.n_outputs = n_outputs\n",
    "        self.center_x = dim[1] // 2\n",
    "        self.center_y = dim[0] // 2\n",
    "        self.col = evt['x'].astype('int')\n",
    "        self.row = evt['y'].astype('int')\n",
    "        self.data = evt['q']\n",
    "        self.head = np.array([evt['xhead'],evt['yhead']])\n",
    "        self.tail = np.array([evt['xvtx'],evt['yvtx']])\n",
    "        self.rotation_angle = self.get_rotation_angle()\n",
    "        \n",
    "        '''Rotation matrices, backward rotation is used to translate track segments back to original'''\n",
    "        self.forward_rotation = self.generate_rotation_matrix(self.rotation_angle)\n",
    "        self.reverse_rotation = np.linalg.inv(self.forward_rotation)\n",
    "        \n",
    "        '''Rotate head and tail to rotated space'''\n",
    "        self.rothead = self.rotate_coord(self.head[::-1],self.forward_rotation)\n",
    "        self.rottail = self.rotate_coord(self.tail[::-1],self.forward_rotation)\n",
    "        \n",
    "        #print(self.rotate_coord(self.rothead,self.reverse_rotation))\n",
    "        '''Generate rotated sparse image'''\n",
    "        self.rot_im = self.rotate_sparse_image()\n",
    "        \n",
    "        '''Get segmented coordinates in rotated space'''\n",
    "        self.rot_segments = np.array(self.get_segment_coordinates()).T\n",
    "        self.segments = []\n",
    "        self.segments.append((evt['xvtx'],evt['yvtx']))\n",
    "        for coord in self.rot_segments:\n",
    "            self.segments.append(self.rotate_coord(coord,self.reverse_rotation)[::-1])\n",
    "        self.segments.append((evt['xhead'],evt['yhead']))\n",
    "    def get_rotation_angle(self):\n",
    "        vec = np.array([self.head[0]-self.tail[0],self.head[1]-self.tail[1]])\n",
    "        theta = np.arctan2(vec[1],vec[0])\n",
    "        return theta\n",
    "\n",
    "    def generate_rotation_matrix(self,theta):\n",
    "        cos_angle = np.cos(theta)\n",
    "        sin_angle = np.sin(theta)\n",
    "        \n",
    "        rotation_matrix = np.array([\n",
    "            [cos_angle, sin_angle],\n",
    "            [-sin_angle, cos_angle]\n",
    "        ])\n",
    "            \n",
    "        return rotation_matrix\n",
    "\n",
    "    def rotate_sparse_image(self):\n",
    "        sparse_matrix = coo_matrix((self.data, (self.row, self.col)), shape=(1152,2048))\n",
    "        # Center of the image\n",
    "\n",
    "        # Translate coordinates to origin\n",
    "        translated_x = self.col - self.center_x\n",
    "        translated_y = self.row - self.center_y\n",
    "\n",
    "        # Apply rotation\n",
    "        new_coords = np.dot(self.forward_rotation, np.array([translated_x, translated_y]))\n",
    "\n",
    "        new_x = np.round(new_coords[0] + self.center_x).astype('int')\n",
    "        new_y = np.round(new_coords[1] + self.center_y).astype('int')\n",
    "\n",
    "        # Filter out-of-bounds coordinates\n",
    "        valid_mask = (new_x >= 0) & (new_x < sparse_matrix.shape[1]) & (new_y >= 0) & (new_y < sparse_matrix.shape[0])\n",
    "        new_x = new_x[valid_mask]\n",
    "        new_y = new_y[valid_mask]\n",
    "        new_data = self.data[valid_mask]\n",
    "\n",
    "        # Create the rotated sparse matrix\n",
    "        rotated_sparse_matrix = coo_matrix((new_data, (new_y, new_x)), shape=sparse_matrix.shape)\n",
    "        return rotated_sparse_matrix.toarray().T\n",
    "    \n",
    "    def rotate_coord(self,coord,rot):\n",
    "        original_coordinate = coord\n",
    "\n",
    "        # Translate coordinate to origin\n",
    "        translated_x = original_coordinate[1] - self.center_x\n",
    "        translated_y = original_coordinate[0] - self.center_y\n",
    "\n",
    "        # Apply rotation\n",
    "        new_coord = np.dot(rot, np.array([translated_x, translated_y]))\n",
    "\n",
    "        # Translate back to the original coordinate system\n",
    "        new_coordinate = (new_coord[1] + self.center_y, new_coord[0] + self.center_x)\n",
    "        return new_coordinate\n",
    "    \n",
    "    def get_segment_coordinates(self):\n",
    "        n_partitions = self.n_outputs+2\n",
    "        y_segments = np.linspace(self.rottail[1],self.rothead[1],n_partitions)[1:-1]\n",
    "        x_segments = []\n",
    "        for seg in y_segments:\n",
    "            if self.mode == 'max':\n",
    "                x_coord = np.median(np.where(self.rot_im[int(np.round(seg)),:] == self.rot_im[int(np.round(seg)),:].max())[0])\n",
    "            elif self.mode == 'median':\n",
    "                indices = pd.Series(self.rot_im[int(np.round(seg)),:]).nlargest(9).index.to_numpy()\n",
    "                x_coord = np.median(indices)\n",
    "            x_segments.append(x_coord)\n",
    "        x_segments = np.array(x_segments)\n",
    "        if np.mean(x_segments) != 575.5 and np.mean(x_segments) != 4:\n",
    "            return x_segments,y_segments\n",
    "        else:\n",
    "            raise ValueError(\"Bad rotation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bed3eb0",
   "metadata": {},
   "source": [
    "### Let's add keypoints and YOLO information more succinctly than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981faef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''There\"s an apparent bug in the keypoint generation code where certain kinds of rotations mess things up.\n",
    "I\"ve figured out how to flag these, but haven\"t figured out how to fix this. Nevertheless, since this is\n",
    "meant to be a minimal working example, we won\"t sweat this. Because of this bug, there will be a preferred \n",
    "direction in the trajectories that do generate. Generally speaking training on a preferred direction will \n",
    "bias a machine learning model which we don\"t want.'''\n",
    "\n",
    "ERs = ERs.query('200 > htlength > 50')\n",
    "ERs.index = [i for i in range(0,len(ERs))]\n",
    "\n",
    "good_indices = []\n",
    "coords = {} #dictionary filled with keypoint tuples\n",
    "for i in range(0,conf['maxNumKeyPoints']):\n",
    "    coords[i] = []\n",
    "\n",
    "for i in tqdm(range(0,len(ERs))):\n",
    "    try:\n",
    "        a = generate_keypoints(ERs,i,n_outputs=conf['maxNumKeyPoints']-2,mode='median')\n",
    "        good_indices.append(i)\n",
    "        for j in range(0,len(a.segments)):\n",
    "            coords[j].append(a.segments[j])\n",
    "    except:\n",
    "        #print(\"Bad rotation\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab58506",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Reduce our dataframe to only include entries where the trajectory generated'''\n",
    "ERs = ERs.loc[ERs.index.isin(good_indices)] #only keep the events where the loop above didnt fail\n",
    "ERs.index = [i for i in range(0,len(ERs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d2876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Make class_index, x, y, width, and height columns'''\n",
    "\n",
    "ERs['class_index'] = 0\n",
    "\n",
    "'''Columns \"x\", \"y\", and \"q\" are array-based quantities. We can use pandas\"s apply function and\n",
    "lambda expressions to do array operations rowwise in a succinct way. Don\"t worry if this notation\n",
    "seems cryptic, once you get used to it, it\"s very succinct and efficient for array operations\n",
    "in pandas dataframes'''\n",
    "\n",
    "ERs['xBB'] = ERs['x'].apply(lambda x: (x.max()+x.min())/2 / conf['cameraX']) #normalized as a fraction of width of image (2048 pixels)\n",
    "ERs['yBB'] = ERs['y'].apply(lambda x: (x.max()+x.min())/2 / conf['cameraY']) #normalized as a fraction of height of image (1152 pixels)\n",
    "ERs['width'] = ERs['x'].apply(lambda x: (x.max()-x.min()) / conf['cameraX'])\n",
    "ERs['height'] = ERs['y'].apply(lambda x: (x.max()-x.min()) / conf['cameraY'])\n",
    "\n",
    "'''Puts key point tuples into into columns p0 to pN'''\n",
    "for key in coords.keys():\n",
    "    ERs['p%s'%(key)] = coords[key]\n",
    "    \n",
    "'''Expands the tuples to p0x, p0y, p1x, p1y, etc.'''\n",
    "# Initialize an empty dictionary to hold the new columns\n",
    "new_columns = {}\n",
    "\n",
    "# Iterate over each of the keypoint columns in the DataFrame\n",
    "for col in ERs.columns[int(-1*conf['maxNumKeyPoints']):]: #apologies that this is\n",
    "    # Extract x and y components from each column\n",
    "    ERs[[f'{col}x', f'{col}y']] = pd.DataFrame(ERs[col].tolist(), index=ERs.index)\n",
    "    # Drop the original column\n",
    "    ERs.drop(columns=[col], inplace=True)\n",
    "    \n",
    "'''Normalize keypoints'''\n",
    "for i in range(0,conf['maxNumKeyPoints']):\n",
    "    ERs['p%sx'%(i)] = ERs['p%sx'%(i)]/conf['cameraX']\n",
    "    ERs['p%sy'%(i)] = ERs['p%sy'%(i)]/conf['cameraY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a314d338",
   "metadata": {},
   "source": [
    "# Now onto something new: Making realistic simulation\n",
    "We can add dark frames to simulation to create noisy images that are more representative of real data. When adding noise, however, there are a couple of effects that need to be simulated:\n",
    "(1) Gain. We need to scale the light yield of the track relative to noise to match data. Figuring this out is a project in and of itself and something we've already done, so I'll use the scaling I use for Migdal simulation here.\n",
    "(2) Vignetting: Vignetting is a known effec tin CMOS cameras where the pixel intensity decreases radially outward from the optical center. This is another effect that we've already simulated so I'll include that here as well. Vignetting is a position dependent effect, so we should randomize track locations before applying vignetting.\n",
    "\n",
    "**Generally speaking, randomizing the locations of tracks along the readout is a good idea, as it makes trained ML models generalize better. If your model is only trained on identifying objects near the center of the readout, it will become *very* good at doing that, and only that. If a model is trained on tracks randomly scattered across the entire readout plane, then it will learn how to look for tracks regardless of position**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba3173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_random_shift(i,border):\n",
    "    tmp = ERs.iloc[i]\n",
    "    #Determine track boundaries\n",
    "    xmin = tmp['x'].min()\n",
    "    xmax = tmp['x'].max()\n",
    "    ymin = tmp['y'].min()\n",
    "    ymax = tmp['y'].max()\n",
    "    \n",
    "    #Perform random uniform shifts in x and y\n",
    "    xshift = np.random.randint(-1*xmin+border,2048-xmax-border)\n",
    "    yshift = np.random.randint(-1*ymin+border,1152-ymax-border)\n",
    "\n",
    "    return xshift, yshift\n",
    "\n",
    "'''Put the shift values in the dataframe so we can then apply them to other columns\n",
    "in the dataframe, thereby shifting the tracks'''\n",
    "xshifts = []\n",
    "yshifts = []\n",
    "for i in range(0,len(ERs)):\n",
    "    xshift,yshift = determine_random_shift(i,border = 150)\n",
    "    xshifts.append(xshift)\n",
    "    yshifts.append(yshift)\n",
    "ERs['xshift'], ERs['yshift'] = xshifts, yshifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Columns that are normalized (width and height stay the same)'''\n",
    "xcols = ['xBB'] + ['p%sx'%(i) for i in range(0,conf['maxNumKeyPoints'])]\n",
    "ycols = ['yBB'] + ['p%sy'%(i) for i in range(0,conf['maxNumKeyPoints'])]\n",
    "\n",
    "'''Unnormalize, shift, and then renormalize'''\n",
    "for col in xcols:\n",
    "    ERs[col] = (ERs[col]*conf['cameraX']+ERs['xshift'])/conf['cameraX']\n",
    "\n",
    "for col in ycols:\n",
    "    ERs[col] = (ERs[col]*conf['cameraY']+ERs['yshift'])/conf['cameraY']\n",
    "    \n",
    "'''Columns that are not normalized'''\n",
    "xcols = ['xvtx','xhead','x']\n",
    "ycols = ['yvtx','yhead','y']\n",
    "\n",
    "for col in xcols:\n",
    "    ERs[col] = (ERs[col]+ERs['xshift'])\n",
    "\n",
    "for col in ycols:\n",
    "    ERs[col] = (ERs[col]+ERs['yshift']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574c1092",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Apply intensity scaling to match gains representative of data'''\n",
    "tqdm.pandas()\n",
    "\n",
    "'''These gain scaling factors were empirically determined'''\n",
    "res_fact = 0.115\n",
    "gf = 5\n",
    "\n",
    "def calc_light_fraction(dist,QE,f=25,N=0.85,reflect=False):\n",
    "    L = 0.5*(1 - np.sqrt( 1 - (f/(2*N*dist))*(f/(2*N*dist)) ))\n",
    "    if reflect:\n",
    "        L += 0.67*0.67*0.33*L*(dist/(dist + 2 + 2*0.57))**2\n",
    "    return L*QE*0.34\n",
    "\n",
    "light_frac = calc_light_fraction(118.7,0.23, reflect = True)\n",
    "\n",
    "def scale_evt(evt,gain_factor,light_fraction):\n",
    "    return evt*light_fraction*gain_factor/0.11\n",
    "\n",
    "def apply_gain_scaling(df,res_fact, gf):\n",
    "    df['scaled_q'] = df['q'].progress_apply(lambda x: scale_evt(x*np.random.normal(1,res_fact),gain_factor=gf,light_fraction=light_frac))\n",
    "    df['scaled_q'] = df['scaled_q'].apply(lambda x: np.round(x).astype('int16'))\n",
    "    df['idx'] = df['scaled_q'].apply(lambda x: np.where(x > 0)[0])\n",
    "    df['scaled_qsum'] = df['scaled_q'].apply(lambda x: x.sum())\n",
    "\n",
    "    df['x'] = [df['x'].iloc[i][df['idx'].iloc[i]].astype('int16') for i in tqdm(range(0,len(df)))]\n",
    "    df['y'] = [df['y'].iloc[i][df['idx'].iloc[i]].astype('int16') for i in tqdm(range(0,len(df)))]\n",
    "    df['scaled_q'] = [df['scaled_q'].iloc[i][df['idx'].iloc[i]].astype('int16') for i in tqdm(range(0,len(df)))]\n",
    "\n",
    "    \n",
    "apply_gain_scaling(ERs,gf=gf,res_fact=res_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927bfeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Simulate vignetting'''\n",
    "\n",
    "def apply_vignetting(df,a):\n",
    "    '''Define centroids. We apply vignetting radially outward'''\n",
    "    centroidx = 1023\n",
    "    centroidy = 575\n",
    "    \n",
    "    df['x'] = df['x'].apply(lambda x: x.astype('float32'))\n",
    "    df['y'] = df['y'].apply(lambda x: x.astype('float32'))\n",
    "    \n",
    "    '''Compute distance from centroids'''\n",
    "    df['dist_x'] = df['x'].apply(lambda x: (x-centroidx)*80/2048)\n",
    "    df['dist_y'] = df['y'].apply(lambda x: (x-centroidy)*80/2048)\n",
    "    df['dist'] = [np.sqrt(df['dist_x'].iloc[i]**2+df['dist_y'].iloc[i]**2) for i in range(0,len(df))]\n",
    "    \n",
    "    '''Apply intensity suppression due to vigentting'''\n",
    "    df['vignetted_q'] = [df['scaled_q'].iloc[i]/(a**2/(a-df['dist'].iloc[i])**2) for i in range(0,len(df))]\n",
    "    df['vignetted_q'] = df['vignetted_q'].apply(lambda x: np.round(x).astype('int16'))\n",
    "    del(df['dist_x'])\n",
    "    del(df['dist_y'])\n",
    "    del(df['dist'])\n",
    "    \n",
    "    ''' This code removes all charge that's 0 after correcting for vignetting and turning into an integer '''\n",
    "    df['x'] = df['x'].apply(lambda x: x.astype('int16'))\n",
    "    df['y'] = df['y'].apply(lambda x: x.astype('int16'))\n",
    "    \n",
    "    df['idx'] = df['vignetted_q'].apply(lambda x: np.where(x > 0)[0])\n",
    "    df['x'] = [df['x'].iloc[i][df['idx'].iloc[i]].astype('int16') for i in tqdm(range(0,len(df)))]\n",
    "    df['y'] = [df['y'].iloc[i][df['idx'].iloc[i]].astype('int16') for i in tqdm(range(0,len(df)))]\n",
    "    df['vignetted_q'] = [df['vignetted_q'].iloc[i][df['idx'].iloc[i]].astype('int16') for i in tqdm(range(0,len(df)))]\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a484819",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERs = apply_vignetting(ERs,a=95) #a is also empirically determined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd1ea5",
   "metadata": {},
   "source": [
    "### Now we've applied both gain and vignetting scalings to the intensities. The next step is to add noise. Rather than simulating noise, it's best to use dark frames recorded by MIGDAL. Dark frames are those where the camera captures images with the rest of the MIGDAL TPC powered down. The noise distribution varies so we pick dark frames at random from a sample of 200 (we could pick more but loading dense 2048 x 1152 arrays can fill up system memory pretty quickly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b023924",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "dark = io.imread('../darks/MIG_Dark_0V_230803T130339.DARK.0001.MTIFF',plugin='pil')\n",
    "'''Load masterdark, we will subtract this from the dark frames'''\n",
    "masterdark = np.load('../darks/master_dark_230803.npz')['arr_0']\n",
    "dark = dark - masterdark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78b1dd9",
   "metadata": {},
   "source": [
    "### Let's downsample our dark frames using 4x4 binning. These aren't sparse arrays, so we have to do this differently than what we've been doing previously. Pytorch's AvgPool function is one way to do this. I prefer using it because it can be computed on a GPU which is much faster than on a CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a92c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "ap = nn.AvgPool2d(kernel_size = (4,4),stride = (4,4),divisor_override = 1)\n",
    "darkDownSample = ap(torch.tensor(dark)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86760e0",
   "metadata": {},
   "source": [
    "### Remake our training, validation, and test sets with the shifted data. The noise will only be added to images for YOLO to evaluate (we should add it to our dataframe but we don't need to yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6495282",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(ERs)\n",
    "# Shuffle data\n",
    "ERs = ERs.sample(frac=1,random_state=42) #Random state ensures we get identical shuffles every time for reproducability\n",
    "ERs.index = [i for i in range(0,len(ERs))] #reset index after shuffling\n",
    "ERs['index'] = ERs.index\n",
    "data = {} #dictionary storing train, validation, and test datasets\n",
    "data['train'] = ERs[:int(dataset_size*0.7)]\n",
    "data['valid'] = ERs[int(dataset_size*0.7):int(dataset_size*0.9)]\n",
    "data['test'] =  ERs[int(dataset_size*0.9):]\n",
    "print('Train set size: %s\\nval set size : %s\\ntest set size: %s\\nsum : %s\\ndataset size: %s'%(len(data['train']),len(data['valid']),len(data['test']),len(data['train'])+len(data['valid'])+len(data['test']),dataset_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be5b351",
   "metadata": {},
   "source": [
    "### Now we generate noisy pngs. The image processing code is a tiny bit different than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image\n",
    "def save_images(settype):\n",
    "    \n",
    "    if settype.lower() != 'train' and settype.lower() != 'test' and settype.lower() !='valid':\n",
    "        raise ValueError(\"settype must be 'train','valid',or 'test'\")\n",
    "    \n",
    "    path = conf['project_dir'] + '/datasets/%s%s/images'%(settype.lower(),conf['suffix'])\n",
    "    print(f\"Saving images to path: {path}\")\n",
    "    \n",
    "    #Create our output directory if it doesn't already exist\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    for i in tqdm(range(0,len(data[settype.lower()]))):\n",
    "        \n",
    "        tmp = data[settype.lower()].iloc[i]\n",
    "        \n",
    "        '''Setting bins to (512,288) downsamples the image with 4x4 binning'''\n",
    "        im = np.histogram2d(tmp['x'],tmp['y'],weights=tmp['vignetted_q'],bins=(512,288),range=((0,2048),(0,1152)))[0].T\n",
    "        \n",
    "        '''Add noise'''\n",
    "        dark_idx = np.random.randint(0,200)\n",
    "        im += darkDownSample[dark_idx]\n",
    "        \n",
    "        '''The colorscale (vmin and vmax) as well as how we define im depend on if we use linear or logarithmic\n",
    "        colorscale images'''\n",
    "        if conf['log_scale'] == False:\n",
    "            matplotlib.image.imsave('%s/%s.png'%(path,tmp['index']), im, vmin=-100, vmax=600,cmap = 'jet')\n",
    "        else:\n",
    "            im[im<0] = 0 #We probably shouldn't do this but this allows for clean log scale images\n",
    "            im = np.log10(im+1)\n",
    "            matplotlib.image.imsave('%s/%s.png'%(path,tmp['index']), im, vmin=1.4, vmax=2.5,cmap = 'jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2224d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['train','valid','test']:\n",
    "    save_images(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9cf0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Ditto here: whether or not we use a log scale is determined from master_configuration.yaml'''\n",
    "def save_labels(settype):\n",
    "    if settype.lower() != 'train' and settype.lower() != 'test' and settype.lower() !='valid':\n",
    "        raise ValueError(\"settype must be 'train','valid',or 'test'\")\n",
    "\n",
    "    path = conf['project_dir'] + '/datasets/%s%s/labels/'%(settype.lower(),conf['suffix'])\n",
    "    print(f\"Saving labels to path: {path}\")\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    for i in range(0,len(data[settype.lower()])):\n",
    "        tmp = data[settype.lower()].iloc[i]\n",
    "        series = tmp[['class_index','xBB', 'yBB', 'width','height'] + list(np.array([['p%sx'%(i), 'p%sy'%(i)] for i in range(0,conf['maxNumKeyPoints'])]).flatten())]\n",
    "        with open(path+'%s.txt'%(tmp['index']), 'w') as f:\n",
    "            series_str = ' '.join(map(str, series.values))\n",
    "            f.write(series_str + '\\n')\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['train','valid']:\n",
    "    save_labels(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d33e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Noisy data files. The track shifts are randomized so we save separate sets for linear and log colorscale\n",
    "for key in ['train','valid','test']:\n",
    "    data[key].index = [i for i in range(0,len(data[key]))]\n",
    "    outfile = path = conf['project_dir'] + \"/data/%s%s.feather\"%(key,conf['suffix'])\n",
    "    print(f\"Saving metadata to {outfile}\")  \n",
    "    data[key].to_feather(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e488f65",
   "metadata": {},
   "source": [
    "### Now we can finally train on our realistic noisy sim and then compare the keypoints to truth in the part2 notebookcript running overnight, or sending your data to Jeff so he can train it on a GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af977158",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt.create_keypoint_config('../master_configuration.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06057e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a base model\n",
    "model = YOLO('yolov8m-pose.yaml')  # load empty model. Can choose from yolov8{n,s,m,l,x}-pose.yaml. Letters are ordered from smallest model to largest\n",
    "\n",
    "#Function to train YOLO\n",
    "#The project field sets the directory where YOLO's trained weights will be assigned\n",
    "model.train(data='/home/jeef/workspace/migKeyPoint/migKeyPoint/tutorial/configs/keypoint.yaml',project=conf['project'],epochs=1000,patience=25,imgsz=512,rect=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5f35b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
